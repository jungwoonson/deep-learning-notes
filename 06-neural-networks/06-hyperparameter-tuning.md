# 하이퍼파라미터 튜닝 (Hyperparameter Tuning)

## 왜 알아야 하는가 (Why This Matters for VLA)

하이퍼파라미터(Hyperparameter)는 모델이 **스스로 학습하지 못하는** 설정값이다. 학습률, 배치 크기, 네트워크 구조 등이 여기에 해당한다. 같은 모델이라도 하이퍼파라미터에 따라 성능이 천지차이이며, 대규모 모델일수록 한 번의 실험 비용이 크기 때문에 체계적인 튜닝이 필수적이다.

VLA와의 연결 고리:
- VLA 학습은 **한 번의 실험에 수백~수천 GPU-hour**가 소요된다
  - 잘못된 하이퍼파라미터로 3일을 학습하고 실패하면 막대한 비용 손실
  - 체계적인 튜닝 전략이 연구 효율을 결정한다
- VLA 논문에서 공개하는 하이퍼파라미터를 **이해하고 재현**할 수 있어야 한다
  - "AdamW, lr=2e-5, warmup=500, cosine decay, batch=256"의 의미를 알아야 함
- VLA 파인튜닝 시 **기본 설정에서 출발하여 소규모 실험으로 탐색**하는 능력이 중요하다
  - 사전학습된 모델의 하이퍼파라미터를 파인튜닝 상황에 맞게 조정

---

## 핵심 개념 (Core Concepts)

### 1. 파라미터 vs 하이퍼파라미터 (Parameters vs Hyperparameters)

```
파라미터 (Parameters):
  - 모델이 학습 중에 자동으로 업데이트하는 값
  - 예: 가중치(W), 편향(b), Norm의 gamma/beta
  - 역전파 + 옵티마이저가 조절

하이퍼파라미터 (Hyperparameters):
  - 학습 전에 사람이 설정하는 값
  - 학습 과정에서 자동으로 바뀌지 않음
  - 예: 학습률, 배치 크기, 은닉 차원, 층 수, dropout 비율
```

### 2. 주요 하이퍼파라미터 분류

#### 학습 관련 (Training)

```
학습률 (Learning Rate):
  - 가장 중요한 하이퍼파라미터
  - 너무 크면 발산, 너무 작으면 수렴이 느림
  - 일반적인 범위:
    사전학습: 1e-4 ~ 3e-4
    파인튜닝: 1e-5 ~ 5e-5
    작은 모델: 1e-3 ~ 1e-2

배치 크기 (Batch Size):
  - GPU 메모리와 성능에 모두 영향
  - 큰 배치: 안정적이지만 일반화 성능 저하 가능, 더 많은 GPU 메모리
  - 작은 배치: 노이즈가 정규화 효과, 하지만 불안정
  - 일반적: 32, 64, 128, 256
  - VLA 사전학습: 256 ~ 2048 (여러 GPU에 분산)

에폭 수 (Number of Epochs):
  - 전체 데이터를 몇 바퀴 학습할지
  - early stopping과 함께 사용하는 것이 일반적
  - 대규모 모델: 에폭보다 총 step 수로 관리

Weight Decay:
  - L2 정규화의 강도
  - AdamW 기준: 0.01 ~ 0.1
  - 0이면 정규화 없음, 너무 크면 underfitting
```

#### 아키텍처 관련 (Architecture)

```
은닉 차원 (Hidden Dimension):
  - 모델의 용량(capacity)을 결정
  - 크면 표현력 높지만 연산/메모리 비용 증가
  - Transformer: d_model = 256, 512, 768, 1024, 2048, 4096, ...

층 수 (Number of Layers / Depth):
  - 모델의 깊이
  - 깊을수록 복잡한 함수 표현 가능하지만 학습 어려움 증가
  - Transformer: 6, 12, 24, 32, 48, ...

Attention Head 수:
  - Multi-Head Attention의 head 수
  - d_model / head_dim = head 수 (보통 head_dim = 64 또는 128)

FFN 확장 비율:
  - FFN 은닉 차원 = d_model의 몇 배인지
  - 전통적: 4배, SwiGLU: 8/3배 (Llama 2)

Dropout 비율:
  - 0.0 ~ 0.5
  - Transformer: 보통 0.1
  - 파인튜닝: 보통 0.0 ~ 0.1
```

### 3. Grid Search (격자 탐색)

모든 하이퍼파라미터 조합을 **체계적으로** 시도한다.

```
예시: 학습률과 배치 크기를 동시에 탐색

학습률: [1e-5, 1e-4, 1e-3]
배치 크기: [32, 64, 128]

격자:
          batch=32    batch=64    batch=128
lr=1e-5:   실험 1      실험 2      실험 3
lr=1e-4:   실험 4      실험 5      실험 6
lr=1e-3:   실험 7      실험 8      실험 9

총 실험 수: 3 × 3 = 9개

모든 조합을 시도하여 최적의 조합을 찾음.
```

**장점과 단점**:
```
장점:
  - 구현이 간단하고 직관적
  - 모든 조합을 빠짐없이 탐색
  - 결과를 표로 정리하기 쉬움

단점:
  - 하이퍼파라미터 수가 늘면 조합이 기하급수적으로 증가 (차원의 저주)
  - 3개 하이퍼파라미터 × 각 5개 값 = 125개 실험
  - 대규모 모델에서는 비용이 너무 큼
```

### 4. Random Search (무작위 탐색)

하이퍼파라미터를 **무작위로** 샘플링하여 시도한다.

```
예시: 학습률과 배치 크기를 무작위로 탐색

학습률: log-uniform(1e-5, 1e-2)에서 무작위 샘플링
배치 크기: [32, 64, 128, 256]에서 무작위 선택

9개의 무작위 조합:
  실험 1: lr=3.2e-4, batch=128
  실험 2: lr=7.1e-5, batch=64
  실험 3: lr=2.8e-3, batch=32
  ...

Grid Search는 정해진 점만 탐색:    Random Search는 더 넓게 탐색:
  lr                                 lr
  |  *  *  *                         |    *     *
  |  *  *  *                         |  *         *
  |  *  *  *                         |       *
  +----------batch                   |  *       *
  (격자점만)                          +----------batch
                                     (다양한 영역 커버)
```

**Random Search가 Grid Search보다 효율적인 이유**:
```
핵심 관찰: 대부분의 경우 일부 하이퍼파라미터만 성능에 큰 영향을 미침

예: 학습률은 성능에 큰 영향, 배치 크기는 작은 영향인 경우

Grid Search (9개 실험):
  학습률을 3개 값만 시도 (나머지는 배치 크기 변형)
  → 학습률 탐색이 부족

Random Search (9개 실험):
  학습률을 9개의 서로 다른 값으로 시도
  → 중요한 하이퍼파라미터를 더 촘촘히 탐색

→ 같은 실험 수로 더 좋은 결과를 찾을 확률이 높음
```

### 5. Learning Rate Finder (학습률 탐색기)

최적의 학습률 범위를 **한 번의 실험**으로 대략적으로 찾는 기법.

```
방법:
  1. 매우 작은 학습률(예: 1e-7)에서 시작
  2. 매 배치마다 학습률을 조금씩 증가 (지수적)
  3. 각 학습률에서의 손실을 기록
  4. 손실이 가장 빠르게 감소하는 학습률 범위를 찾음

그래프:
  loss
  |\.
  |  '-.
  |     '-._        /  ← 손실이 다시 증가 (lr이 너무 큼)
  |         '-.___/
  +-----|-------|------→ lr (log scale)
     1e-5    1e-3    1e-1
              ↑
         이 부근이 최적의 학습률

실전 팁:
  - 손실이 가장 빠르게 감소하는 지점보다 약간 낮은 lr을 선택
  - "최솟값"이 아니라 "가장 가파르게 하강하는 곳"을 선택
  - 최적 lr / 10 정도를 peak lr로 사용하는 경우도 많음
```

### 6. 학습률과 배치 크기의 관계 (Linear Scaling Rule)

```
핵심 규칙:
  배치 크기를 k배 늘리면, 학습률도 k배 늘린다.

이유:
  배치 크기가 커지면 gradient의 분산이 줄어듦
  → 더 큰 학습률로 더 큰 보폭을 밟아도 안정적
  → 같은 학습 속도를 유지하려면 lr도 비례하여 증가

예시:
  batch=32, lr=1e-4   →   batch=256, lr=8e-4
  (8배 증가)              (8배 증가)

주의:
  - 완벽한 선형 관계는 아님 (특히 매우 큰 배치에서)
  - warmup을 함께 늘려야 할 수 있음
  - 실무에서는 대략적인 가이드라인으로 사용
```

### 7. 실전 튜닝 전략 (Practical Tips)

#### 순서 있는 접근 (Systematic Approach)

```
1단계: 기본값으로 시작
  - 논문이나 유사 프로젝트의 하이퍼파라미터를 그대로 사용
  - "바퀴를 재발명하지 않기"

  VLA 파인튜닝 기본값 예시:
    옵티마이저: AdamW
    학습률: 2e-5
    Weight decay: 0.01
    Warmup: 전체의 3~5%
    스케줄: Cosine decay
    배치 크기: GPU 메모리가 허용하는 최대값

2단계: 학습률 탐색 (가장 먼저)
  - LR Finder 또는 3~5개 학습률로 짧은 실험
  - [1e-5, 5e-5, 1e-4, 5e-4, 1e-3] 시도
  - 각각 전체 학습의 10~20%만 실행하여 빠르게 비교

3단계: 배치 크기 조정
  - GPU 메모리가 허용하는 최대 배치 크기에서 시작
  - gradient accumulation으로 실효 배치 크기 조절

4단계: 정규화 조정
  - 과적합 징후가 있으면: weight decay 증가, dropout 추가
  - 과소적합 징후가 있으면: 정규화 줄이기, 모델 크기 늘리기

5단계: 세부 튜닝
  - warmup 길이, 스케줄 종류, beta2 등
  - 보통 큰 차이를 만들지 않지만 마지막 1~2% 성능에 영향
```

#### 튜닝 시 흔한 실수와 해결

```
실수 1: 한 번에 여러 하이퍼파라미터를 바꿈
  → 무엇이 효과가 있었는지 알 수 없음
  해결: 한 번에 하나씩 변경하고 효과를 관찰

실수 2: 너무 적은 시간 학습 후 판단
  → 초반 loss만 보고 학습률이 나쁘다고 판단
  해결: 최소 전체의 10~20%는 학습 후 비교

실수 3: 검증 세트 없이 튜닝
  → 훈련 성능만 보고 하이퍼파라미터 선택 → 과적합
  해결: 반드시 별도의 검증 세트로 성능 측정

실수 4: 재현성 무시
  → 같은 설정인데 결과가 다름
  해결: 랜덤 시드 고정, 실험 설정을 기록

실수 5: 너무 넓은 범위를 탐색
  → 실험 수가 부족하여 좋은 영역을 놓침
  해결: 논문의 기본값 근처에서 시작하여 점차 확대
```

### 8. VLA 논문의 하이퍼파라미터 읽는 법

실제 VLA 논문에서 보고하는 학습 설정을 이해해보자:

```
예시 (OpenVLA 스타일):
  Backbone: Llama 2-7B
  Vision Encoder: DINOv2 ViT-L/14
  Optimizer: AdamW (beta1=0.9, beta2=0.95)
  Peak LR: 2e-5
  LR Schedule: Cosine decay with linear warmup
  Warmup Steps: 500
  Total Steps: 100,000
  Batch Size: 256 (across 8 GPUs)
  Weight Decay: 0.01
  Gradient Clipping: max_norm=1.0
  Dropout: 0.0

이 설정이 의미하는 것:
  - AdamW + beta2=0.95: 최근 gradient를 더 반영 (0.999보다 빠른 적응)
  - Peak LR 2e-5: 파인튜닝이므로 사전학습(3e-4)보다 훨씬 낮음
  - Warmup 500 steps: 전체의 0.5% → 빠르게 warming up
  - Batch 256 on 8 GPUs: GPU당 batch 32 → gradient accumulation 가능성
  - Dropout 0.0: 사전학습된 모델을 미세 조정할 때는 dropout을 끄는 경우가 많음
  - Gradient Clipping 1.0: gradient 폭발 방지 (거의 필수)
```

### 9. 하이퍼파라미터 기록과 재현 (Experiment Tracking)

```
실험을 체계적으로 기록하는 것이 장기적으로 가장 중요한 습관이다.

최소한 기록해야 할 것:
  1. 모든 하이퍼파라미터 (변경한 것 + 기본값 모두)
  2. 랜덤 시드
  3. 학습 곡선 (loss, metric over steps)
  4. 최종 성능 (훈련 + 검증)
  5. 총 학습 시간
  6. 특이 사항 (loss spike, NaN 발생 등)

도구:
  - 간단: 텍스트 파일, 스프레드시트
  - 체계적: Weights & Biases (wandb), MLflow, TensorBoard
  - VLA 연구에서는 wandb가 사실상 표준
```

---

## 연습 주제 (Practice Topics)

스스로 생각해보고 답을 정리해 보자 (코드 작성 불필요):

1. **하이퍼파라미터 식별**: 다음 중 "파라미터"와 "하이퍼파라미터"를 구분하라: 학습률, 가중치 행렬, 배치 크기, 편향 벡터, dropout 비율, LayerNorm의 gamma, 은닉 차원 크기, Attention head 수.

2. **Grid vs Random**: 학습률(5개 후보), 배치 크기(3개 후보), dropout(3개 후보)를 Grid Search로 탐색하면 총 몇 번의 실험이 필요한가? 예산이 15회로 제한된다면 Random Search가 왜 더 유리한가?

3. **LR Finder 해석**: LR Finder 그래프에서 loss가 lr=1e-4에서 급격히 감소하기 시작하고, lr=1e-2에서 다시 증가한다. 최적의 학습률을 어떻게 선택하겠는가?

4. **Linear Scaling**: batch_size=64, lr=1e-4로 학습하던 모델을 batch_size=512로 변경한다. Linear Scaling Rule에 따르면 학습률을 얼마로 설정해야 하는가? warmup은 어떻게 조정해야 하는가?

5. **VLA 설정 해석**: 한 VLA 논문이 "AdamW, lr=5e-5, warmup=1000, cosine decay to 0, batch=128, weight_decay=0.1, gradient_clip=1.0"으로 학습했다고 보고했다. 이 모델이 사전학습이 아닌 파인튜닝임을 어떻게 알 수 있는가? (힌트: lr의 크기)

6. **튜닝 전략 설계**: 새로운 로봇 팔에 대해 VLA를 파인튜닝한다고 하자. GPU 4개가 있고 예산은 20번의 실험이다. 어떤 순서로 무엇을 탐색하겠는가? 우선순위를 정하고 이유를 설명하라.

---

## 다음 노트 (Next Note)

신경망의 모든 핵심 구성 요소를 배웠다: 구조(MLP), 활성화 함수, 역전파, 옵티마이저, 정규화, 그리고 하이퍼파라미터 튜닝. 이제 이 기초 위에 **공간적 패턴을 인식하는 특수한 신경망**을 배울 차례이다. VLA의 Vision Encoder가 이미지를 이해하는 방식의 근간이다.

**다음**: [합성곱 직관 (Convolution Intuition)](../07-cnn/) - 이미지의 공간적 구조를 활용하는 CNN의 핵심 아이디어. VLA의 시각 인식 능력의 출발점.
