# 대규모 언어 모델

| # | 주제 | 상태 |
|---|------|------|
| 1 | [BERT](01-bert-encoder-models.md) | |
| 2 | [GPT (자기회귀)](02-gpt-autoregressive.md) | |
| 3 | [토크나이징 (BPE)](03-tokenization-bpe.md) | |
| 4 | [사전학습/파인튜닝](04-pretraining-finetuning.md) | |
| 5 | [Llama 아키텍처](05-llama-architecture.md) | |
| 6 | [인스트럭션 튜닝/RLHF](06-instruction-tuning-rlhf.md) | |
| 7 | [LoRA/PEFT](07-lora-peft.md) | |
