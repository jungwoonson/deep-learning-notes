# 과적합과 정규화 (Overfitting and Regularization)

## 왜 알아야 하는가 (Why This Matters for VLA)

아무리 좋은 모델도 **과적합(overfitting)** 되면 실제 환경에서는 쓸모가 없다. VLA 로봇이 훈련 환경에서만 잘 동작하고 새로운 환경에서 실패한다면, 그것은 과적합된 것이다.

VLA와의 연결 고리:
- VLA 모델은 파라미터가 수십억 개에 달하므로 **과적합 위험이 매우 높다**
- 로봇이 학습한 환경(실험실)에서만 잘 동작하고 새로운 환경(실제 가정집)에서 실패하면 과적합이다
- VLA 학습에서 **dropout, weight decay(L2 정규화), data augmentation** 등이 필수적으로 사용된다
- **일반화(generalization)** 능력이야말로 VLA 모델의 가치를 결정한다
- 과적합을 진단하고 방지하는 기술은 모든 딥러닝 프로젝트의 핵심이다

---

## 핵심 개념 (Core Concepts)

### 1. 편향-분산 트레이드오프 (Bias-Variance Tradeoff)

모델의 예측 오차는 두 가지 원인으로 분해된다:

$$\text{총 오차} = \text{Bias}^2 + \text{Variance} + \text{irreducible noise}$$

**편향 (Bias)**:
- 모델이 **너무 단순**해서 데이터의 진짜 패턴을 포착하지 못하는 오류
- "모델의 가정이 현실과 다름"
- 예: 곡선 데이터를 직선으로 피팅하려 함

**분산 (Variance)**:
- 모델이 **너무 복잡**해서 훈련 데이터의 노이즈까지 학습하는 오류
- "데이터가 조금만 바뀌어도 결과가 크게 달라짐"
- 예: 모든 데이터 포인트를 정확히 지나는 고차 다항식

```
높은 Bias (Underfitting):      적절한 모델:           높은 Variance (Overfitting):

  ○   ○                         ○   ○                   ○   ○
 ○  ○   ○                      ○  ○   ○                ○  ○   ○
 ──────── (직선)              ○ ~~~~~○ (적절한 곡선)    ○/\/\/\○ (모든 점을 지남)
○     ○                      ○       ○                ○       ○

"패턴을 못 찾음"             "진짜 패턴을 찾음"       "노이즈까지 외움"
```

**트레이드오프**:
```
오차
 |  \          /
 |   \   /\  /
 |    \ / Variance
 |     X
 |    / \
 |   /   \___
 |  / Bias
 +------------------→ 모델 복잡도
   단순          복잡

→ 최적점은 Bias와 Variance가 만나는 지점
```

### 2. 과적합과 과소적합 (Overfitting vs. Underfitting)

#### 과소적합 (Underfitting)
```
증상:
- 훈련 손실 높음 + 검증 손실 높음
- 모델이 너무 단순하거나, 학습이 부족함

원인: 모델 용량 부족, 학습 시간 부족, 특성 부족
해결: 더 복잡한 모델 사용, 더 오래 학습, 더 많은 특성 추가
```

#### 과적합 (Overfitting)
```
증상:
- 훈련 손실 낮음 + 검증 손실 높음 (두 손실 사이의 격차가 큼)
- 모델이 훈련 데이터를 "외워버림"

원인: 모델이 너무 복잡, 데이터 부족, 정규화 없음
해결: 정규화 기법 적용 (아래에서 설명)
```

**손실 그래프로 진단하기**:
```
정상 학습:              과적합:                 과소적합:
loss                    loss                    loss
 |\ train               |\ train               |\ train ≈ val
 | \  val               | \  val               | \
 |  '-._               |  '._     ↗ val      |  '--------
 |      '-._           |     '._/             |
 |          '-._       |        '._train      |
 +---------epoch       +---------epoch        +---------epoch

(두 곡선 모두 감소,     (train은 감소하나        (둘 다 높은 수준에서
 격차가 작음)            val은 다시 상승)          정체)
```

### 3. L1 정규화 (Lasso Regularization)

손실 함수에 가중치의 **절대값 합**을 추가한다.

$$L_{\text{total}} = L_{\text{original}} + \lambda \sum_i |w_i|$$

$\lambda$: 정규화 강도 (하이퍼파라미터)

**특성**:
- 일부 가중치를 정확히 **0으로 만듦** → 불필요한 특성을 자동으로 제거 (feature selection)
- 모델을 **희소(sparse)** 하게 만든다
- 0에서 미분 불가능하므로 subgradient를 사용

```
L1의 효과:
가중치 [0.5, 0.3, 0.001, 0.8, 0.002]
  → L1 적용 후: [0.4, 0.2, 0.0, 0.7, 0.0]  (작은 가중치가 0이 됨)
  → 특성 3과 5는 모델에서 사실상 제거됨
```

### 4. L2 정규화 (Ridge Regularization / Weight Decay)

손실 함수에 가중치의 **제곱 합**을 추가한다.

$$L_{\text{total}} = L_{\text{original}} + \lambda \sum_i w_i^2$$

→ 딥러닝에서는 이것을 "Weight Decay"라고 부른다

**특성**:
- 가중치를 0으로 만들지는 않지만, **전체적으로 작게** 만든다
- 큰 가중치에 더 큰 페널티를 부여한다
- 모델이 특정 특성에 과도하게 의존하는 것을 방지한다
- **딥러닝에서 가장 널리 사용되는 정규화 기법** 중 하나이다

```
L2의 효과:
가중치 [0.5, 0.3, 3.0, 0.8, 2.5]
  → L2 적용 후: [0.45, 0.27, 1.2, 0.72, 1.0]  (큰 값이 많이 줄어듦)
  → 모든 가중치가 고르게 작아지되, 큰 것일수록 더 많이 줄어듦
```

**L1 vs L2 비교**:

| 구분 | L1 (Lasso) | L2 (Ridge / Weight Decay) |
|------|-----------|---------------------------|
| 페널티 | $\sum |w_i|$ | $\sum w_i^2$ |
| 효과 | 희소 모델 (일부 가중치 = 0) | 작은 가중치 모델 (모든 가중치 축소) |
| 특성 선택 | 자동으로 수행 | 수행하지 않음 |
| 딥러닝 사용 | 드묾 | 매우 흔함 (weight decay) |

### 5. 조기 종료 (Early Stopping)

검증 손실이 더 이상 줄어들지 않으면 학습을 **일찍 멈추는** 기법이다.

```
loss
 |\ train
 | \  val
 |  '-._     ↗  (검증 손실 상승 시작)
 |      '._/|
 |         '.|_train
 +-----------|----epoch
             ↑
        여기서 멈춤! (early stopping)
```

**구현 방식**:
```
best_val_loss = 무한대
patience = 10  (참을 횟수)
counter = 0

매 에폭:
  if val_loss < best_val_loss:
    best_val_loss = val_loss
    best_model 저장
    counter = 0
  else:
    counter += 1
    if counter >= patience:
      학습 중단, best_model 복원
```

**특징**:
- 구현이 간단하고 효과적이다
- 별도의 하이퍼파라미터는 `patience`뿐이다
- "무료 정규화(free regularization)"라고도 불린다
- VLA를 포함한 거의 모든 딥러닝 학습에서 사용된다

### 6. 교차 검증 (Cross-Validation)

데이터가 적을 때 모델을 더 신뢰성 있게 평가하는 방법이다.

#### K-Fold Cross-Validation
```
데이터를 K개의 폴드(fold)로 나누고, 각 폴드가 한 번씩 검증 세트가 된다.

5-Fold 예시:
Round 1: [Val][Train][Train][Train][Train]  → 성능 85%
Round 2: [Train][Val][Train][Train][Train]  → 성능 82%
Round 3: [Train][Train][Val][Train][Train]  → 성능 88%
Round 4: [Train][Train][Train][Val][Train]  → 성능 84%
Round 5: [Train][Train][Train][Train][Val]  → 성능 86%

최종 성능 = 평균(85, 82, 88, 84, 86) = 85% (±2.1%)
```

**장점**:
- 모든 데이터가 한 번씩 검증에 사용됨 → 평가가 더 안정적
- 성능의 **분산**도 알 수 있음 (얼마나 일관적인지)
- 데이터가 적을 때 특히 유용

**단점**:
- K번 학습해야 하므로 시간이 K배 소요
- 딥러닝에서는 학습 비용이 높아 실무에서 잘 사용하지 않음 (주로 전통적 ML에서 사용)

#### Stratified K-Fold
```
클래스 비율을 유지하면서 폴드를 나눈다.

전체 데이터: 양성 10%, 음성 90%
→ 각 폴드에서도 양성 10%, 음성 90% 비율 유지

→ 클래스 불균형(class imbalance)이 있을 때 필수
```

### 7. 과적합 방지 전략 종합 (Summary of Regularization Strategies)

```
과적합이 의심되면 다음을 순서대로 시도:

1. 더 많은 데이터 수집 (가장 효과적이지만 가장 비쌈)
2. Data Augmentation (기존 데이터를 변형하여 늘림 - CNN 파트에서 자세히)
3. Early Stopping (간단하고 효과적)
4. Weight Decay / L2 정규화
5. Dropout (뉴럴 네트워크 파트에서 자세히)
6. 모델 단순화 (레이어/뉴런 수 줄이기)
```

---

## 연습 주제 (Practice Topics)

스스로 생각해보고 답을 정리해 보자 (코드 작성 불필요):

1. **진단 연습**: 훈련 정확도 99%, 검증 정확도 60%인 모델은 어떤 상태인가? 어떤 조치를 취해야 하는가?

2. **편향-분산 분석**: 훈련 정확도 55%, 검증 정확도 52%인 모델은 어떤 상태인가? (힌트: 둘 다 낮음)

3. **L1 vs L2 선택**: 100개의 특성 중 실제로 중요한 것이 5개뿐이라고 의심될 때, L1과 L2 중 어느 것이 더 적합한가? 이유는?

4. **Early Stopping 설계**: patience를 너무 작게 설정하면(예: 1) 어떤 문제가 생기는가? 너무 크게 설정하면(예: 100)?

5. **VLA 일반화 시나리오**: VLA 로봇이 파란 컵만 집는 연습을 했는데, 빨간 컵은 집지 못한다. 이것은 과적합의 일종인가? 어떻게 해결할 수 있을까?

6. **교차 검증**: 데이터가 500개밖에 없는 의료 진단 문제에서, 왜 단순 train/val/test 분할보다 K-Fold가 더 적절한가?

---

## 다음 노트 (Next Note)

과적합을 방지하고 모델을 잘 학습시켰다면, 이제 그 모델이 **정말 잘 동작하는지 어떻게 측정**하는지 배워야 한다.

**다음**: [평가 지표 (Evaluation Metrics)](./06-evaluation-metrics.md) - 정확도만으로는 부족한 이유와, 다양한 성능 측정 방법을 배운다.
