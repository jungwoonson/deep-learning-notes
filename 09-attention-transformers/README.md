# 어텐션 & 트랜스포머

| # | 주제 | 상태 |
|---|------|------|
| 1 | [어텐션 메커니즘](01-attention-mechanism.md) | |
| 2 | [Self-Attention (Q/K/V)](02-self-attention-qkv.md) | |
| 3 | [Transformer 아키텍처](03-transformer-architecture.md) | |
| 4 | [위치 인코딩 (RoPE)](04-positional-encoding-rope.md) | |
| 5 | [Multi-Head Attention & FFN](05-multi-head-attention-ffn.md) | |
| 6 | [Transformer 구현](06-transformer-implementation.md) | |
