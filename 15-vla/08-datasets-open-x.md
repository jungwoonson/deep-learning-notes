# Datasets & Open X-Embodiment (데이터셋)

## VLA와의 연결

**VLA의 성능은 모델 아키텍처만큼이나 학습 데이터에 의해 결정된다.** OpenVLA가 RT-2에 근접한 성능을 달성한 핵심 요인 중 하나는 Open X-Embodiment라는 대규모 공유 데이터셋이다. 이 노트는 VLA 학습에 사용되는 데이터셋의 구조, 형식, 다양성의 중요성, 그리고 자체 데이터를 준비하는 방법을 다룬다. Part 5(PyTorch Datasets/DataLoaders)에서 배운 데이터 처리 개념이 로봇 도메인에서 어떻게 확장되는지 확인한다.

---

## 핵심 개념

### 1. 왜 데이터가 VLA의 핵심인가

```
LLM의 교훈:
  GPT-3/4의 성능 = 모델 크기 + 데이터 규모 + 데이터 품질
  → "Data is the new oil" (데이터가 새로운 석유)

VLA에서도 동일:
  VLA 성능 = VLM 사전학습 + 로봇 데이터 규모 + 로봇 데이터 다양성

그러나 로봇 데이터의 특수한 어려움:
  1. 수집 비용이 극히 높음
     텍스트: 인터넷에서 크롤링 (거의 무료)
     이미지: 인터넷에서 크롤링 (거의 무료)
     로봇:   실제 로봇으로 텔레오퍼레이션 (시간당 $50-200)

  2. 로봇마다 다른 형태
     텍스트: 모든 언어가 같은 "문자" 형태
     이미지: 모든 카메라가 같은 "픽셀" 형태
     로봇:   로봇마다 관절 수, 범위, 센서가 다름!

  3. 환경 다양성의 부족
     대부분 실험실 환경에서만 수집
     실제 가정/공장 환경과 큰 차이

→ 이 문제를 해결하기 위해 "공유 데이터셋"이 등장
```

### 2. Open X-Embodiment (OXE)

```
Open X-Embodiment 데이터셋:

발표:   2023년 10월 (Google DeepMind 주도)
규모:   1M+ 에피소드 (100만 개 이상의 로봇 궤적)
로봇:   22종의 서로 다른 로봇
기관:   21개 연구 기관 (Google, Stanford, Berkeley, MIT 등)
task:   수백 종류 (집기, 놓기, 밀기, 열기, 닫기 등)

포함된 데이터셋 (주요 예시):
  RT-1 데이터:         130K 에피소드, Google 로봇
  Bridge V2:           60K 에피소드, WidowX 로봇 (Berkeley)
  Toto:                15K 에피소드, Franka Panda
  DROID:               76K 에피소드, Franka, 다양한 환경
  Language Table:      180K 에피소드, 탁상 조작
  ...총 60+ 개별 데이터셋

핵심 가치:
  1. 규모(Scale): 단일 연구실이 수집할 수 없는 대규모 데이터
  2. 다양성(Diversity): 다양한 로봇, 환경, task
  3. 표준화(Standardization): RLDS 형식으로 통일
  4. 접근성(Accessibility): 누구나 무료로 다운로드
```

### 3. RLDS 형식 (Reinforcement Learning Datasets)

```
RLDS: Google에서 만든 로봇 데이터 표준 형식

데이터 구조:
  Dataset
  └── Episode (에피소드: 하나의 task 수행 기록)
      └── Step (스텝: 하나의 타임스텝)
          ├── observation (관측)
          │   ├── image (카메라 이미지, 보통 256x256 또는 224x224)
          │   ├── wrist_image (손목 카메라, 선택적)
          │   └── state (로봇 관절 상태)
          ├── action (행동)
          │   └── [delta_x, delta_y, delta_z, delta_rx, delta_ry, delta_rz, gripper]
          ├── reward (보상, 보통 성공 시 1, 그 외 0)
          ├── is_terminal (에피소드 종료 여부)
          └── language_instruction (자연어 명령)
              예: "pick up the red cup"

저장 형식: TFRecord (TensorFlow Record)
  - 효율적인 바이너리 형식
  - 대규모 데이터의 순차 읽기에 최적화
  - 분산 학습 시 병렬 로딩 가능

하나의 에피소드 예시:
  Episode #42:
    instruction: "pick up the apple and place it on the plate"
    step 0: image_0, state_0, action_0, reward=0
    step 1: image_1, state_1, action_1, reward=0
    ...
    step 45: image_45, state_45, action_45, reward=0
    step 46: image_46, state_46, action_46, reward=1 (성공!)
    총 47 스텝, 약 15초 (3Hz 제어)
```

### 4. LeRobot 커뮤니티 데이터셋

```
LeRobot 데이터셋 (Hugging Face):

Open X-Embodiment와의 차이:
  OXE:     연구 기관이 수집, RLDS/TFRecord 형식
  LeRobot: 커뮤니티가 수집, LeRobot/Parquet 형식

규모 (2025년 기준):
  총 프레임: 10M+ (1000만 프레임 이상)
  데이터셋 수: 487+
  기여자: 전 세계 연구자, 학생, 취미가

LeRobot 데이터 형식:
  Parquet 파일 (Apache Arrow 기반)
  + 이미지는 별도 폴더에 저장

  각 행(row):
  ├── timestamp (시간)
  ├── observation.image (이미지 경로)
  ├── observation.state (관절 상태)
  ├── action (행동)
  └── episode_index (에피소드 번호)

  메타데이터:
  ├── fps (데이터 수집 주파수)
  ├── robot_type (로봇 종류)
  ├── task_description (task 설명)
  └── num_episodes (총 에피소드 수)

주요 로봇:
  SO-100:     저가 로봇 팔 (~$300)
  Koch v1.1:  저가 로봇 팔
  Franka:        연구용 로봇 팔
  Fairino FR3:   연구용 6-DoF 로봇 팔
  WidowX:        연구용 로봇 팔
  ALOHA:         양팔 텔레오퍼레이션 시스템

Hugging Face Hub에서의 접근:
  데이터셋 이름 형식: lerobot/{username}_{robot}_{task}
  예: lerobot/community_so100_pick_cup
  → Hub에서 바로 미리보기, 다운로드 가능
```

### 5. 데이터 다양성의 영향

```
데이터 다양성이 VLA 성능에 미치는 영향:

실험 결과 (OXE 논문):
  단일 로봇 데이터로 학습 vs 다중 로봇 데이터로 학습:

  평가 대상       단일 로봇     다중 로봇     차이
  ──────────────────────────────────────────────
  학습 task        85%           90%         +5%
  새로운 task      45%           70%        +25%  ← 핵심!
  새로운 물체      50%           75%        +25%  ← 핵심!
  새로운 환경      30%           60%        +30%  ← 핵심!

해석:
  다양한 데이터는 "학습 task" 성능보다
  "일반화(generalization)" 성능에 훨씬 큰 영향을 미친다

왜 다양성이 일반화를 돕는가:
  1. 공통 패턴 추출
     다양한 로봇에서 "잡기"의 공통 구조를 학습
     → 새로운 로봇에서도 "잡기"가 가능

  2. 환경 불변성(invariance) 학습
     다양한 배경에서 학습 → 배경에 의존하지 않는 표현
     → 새로운 환경에서도 동작

  3. 물체 다양성
     수백 종류의 물체와 상호작용
     → 새로운 물체에 대한 일반화

Negative Transfer 주의:
  너무 다른 데이터를 섞으면 오히려 성능 하락 가능
  예: 양팔 로봇 데이터가 단일 팔 로봇 학습을 방해
  → 데이터 필터링과 가중치 설정이 중요
```

### 6. 자체 데이터 수집 파이프라인

```
VLA 파인튜닝을 위한 자체 데이터 수집:

1단계: 텔레오퍼레이션 시스템 설정
  방법 A: 리더-팔로워 (Leader-Follower)
    리더 로봇을 사람이 조작 → 팔로워 로봇이 따라함
    예: ALOHA 시스템 (양팔), SO-100 (단일팔)
    장점: 직관적, 자연스러운 동작
    단점: 리더 로봇이 추가로 필요

  방법 B: VR 컨트롤러
    VR 헤드셋/컨트롤러로 로봇을 원격 조작
    예: Meta Quest + custom mapping
    장점: 비교적 저렴, 직관적
    단점: 지연시간(latency) 문제

  방법 C: 스페이스마우스 (3D Mouse)
    3D 마우스로 엔드이펙터 위치/자세 제어
    예: SpaceMouse Compact (~$150)
    장점: 저렴, 간단
    단점: 학습 곡선 필요, 양손 조작 어려움

2단계: 데이터 수집
  - 수집할 task 정의 (예: "컵을 집어서 선반에 놓기")
  - task당 50-200 에피소드 수집 (최소 권장)
  - 다양한 초기 상태 (물체 위치, 방향 변경)
  - 일관된 성공 기준 정의

3단계: 품질 관리
  - 실패 에피소드 필터링
  - 이상 데이터(outlier) 제거
  - 행동 범위 확인 (극단적 값 체크)
  - 이미지 품질 확인 (흐림, 가림 등)
```

### 7. 데이터 형식 변환

```
자체 데이터 → VLA 학습 형식 변환:

원시 데이터 (수집된 그대로):
  - ROS bag 파일 (ROS 기반 로봇)
  - HDF5 파일 (일부 시스템)
  - CSV + 이미지 폴더 (수동 수집)

RLDS 형식으로 변환 (OpenVLA용):
  필요한 정보:
    1. 이미지: JPEG/PNG, 224x224 리사이즈
    2. 행동: 7-DoF 연속값 (정규화 필요)
    3. 언어 명령: 각 에피소드에 대한 텍스트 설명
    4. 에피소드 경계: 시작/종료 표시

  정규화 (Normalization):
    각 행동 차원의 평균과 표준편차를 계산
    action_normalized = (action - mean) / std
    → 모든 차원이 비슷한 범위 (-3 ~ +3)에 있도록

LeRobot 형식으로 변환 (SmolVLA용):
  LeRobot v0.4.3의 데이터 구조:
    dataset/
    ├── data/
    │   ├── chunk-000/
    │   │   ├── episode_000000.parquet
    │   │   ├── episode_000001.parquet
    │   │   └── ...
    │   └── ...
    ├── videos/ (또는 images/)
    │   ├── observation.image/
    │   │   ├── episode_000000.mp4
    │   │   └── ...
    │   └── ...
    └── meta/
        ├── info.json (데이터셋 메타정보)
        ├── stats.json (통계: 평균, 표준편차)
        └── episodes.jsonl (에피소드 목록)
```

### 8. 데이터 규모 가이드라인

```
task 복잡도별 권장 데이터 규모:

단순 task (단일 물체 집기):
  최소: 50 에피소드
  권장: 100-200 에피소드
  예상 수집 시간: 1-3시간

중간 task (집기 + 놓기):
  최소: 100 에피소드
  권장: 200-500 에피소드
  예상 수집 시간: 3-8시간

복잡 task (다단계, 다물체):
  최소: 200 에피소드
  권장: 500-1000 에피소드
  예상 수집 시간: 8-20시간

주의사항:
  1. 질 > 양
     100개의 깨끗한 데모 > 500개의 노이즈 데모
  2. 다양성이 중요
     같은 초기 상태의 100개 < 다양한 초기 상태의 50개
  3. 사전학습 VLA 파인튜닝 시
     사전학습 덕분에 적은 데이터로도 가능 (few-shot)
     50-100 에피소드로도 의미있는 성능 달성 가능
  4. 데이터 증강 활용
     이미지 augmentation (색상, 밝기, 잘라내기)
     → 실질적 데이터 규모 2-5배 증가 효과
```

### 9. 데이터 품질 vs 규모의 트레이드오프

```
데이터 품질의 영향:

실험적 발견:
  깨끗한 데이터 100개    vs   노이즈 데이터 1000개
  결과: 깨끗한 100개가 대부분의 경우 더 좋음

품질에 영향을 미치는 요인:
  1. 조작자의 숙련도
     숙련된 조작자: 부드럽고 효율적인 궤적
     초보 조작자: 불필요한 움직임, 실패 반복

  2. 행동의 일관성
     같은 task를 비슷한 전략으로 수행
     vs 매번 다른 전략으로 수행 (모델이 혼란)

  3. 성공/실패 레이블의 정확성
     실패 에피소드가 성공으로 레이블되면 학습에 악영향

  4. 센서 동기화
     이미지와 행동의 시간 정렬이 어긋나면
     모델이 잘못된 시각-행동 매핑을 학습

커뮤니티의 합의:
  "더 적은 고품질 데이터를 수집하고,
   데이터 증강으로 규모를 키우는 것이 가장 효율적"
```

---

## 연습 주제 (코드 없이 생각해보기)

1. **데이터 비용 계산**: 100 에피소드를 수집하는 데 필요한 시간과 비용을 추정하라. 에피소드당 30초, 준비/초기화에 30초, 시급 $30 가정. 1000 에피소드는? 이것을 텍스트 데이터 수집 비용과 비교하라.

2. **Negative Transfer 시나리오**: 양팔 휴머노이드 데이터와 단일 팔 로봇 데이터를 섞어 학습할 때 발생할 수 있는 문제를 구체적으로 설명하라. 행동 차원의 불일치를 어떻게 처리할 수 있을까?

3. **데이터 다양성 설계**: "컵 집기" task의 데이터를 수집할 때, 어떤 변수들을 다양하게 해야 하는가? (물체 위치, 색상, 크기, 배경, 조명, ... 등) 각 변수의 우선순위를 매겨보라.

4. **정규화의 중요성**: 행동 차원 중 delta_x 범위가 [-0.05, 0.05]m이고 delta_rz 범위가 [-3.14, 3.14]rad일 때, 정규화 없이 학습하면 어떤 문제가 발생하는가? (힌트: Loss Function에서 두 차원의 기여도)

5. **RLDS vs LeRobot 형식**: 두 형식의 차이점을 정리하라. OpenVLA는 RLDS를, SmolVLA는 LeRobot 형식을 사용한다. 왜 두 형식이 공존하는가? 장기적으로 어떤 형식이 표준이 될까?

6. **데이터 증강 전략**: 로봇 데이터에 적용할 수 있는 데이터 증강 기법을 나열하라. 이미지 증강(색상, 밝기)은 적용 가능하지만, 행동 증강은 왜 어려운가? (힌트: 이미지를 뒤집으면 행동도 뒤집어야 함)

---

## 다음 노트

**다음**: [LeRobot으로 파인튜닝](./09-finetuning-lerobot.md) - 데이터가 준비되었으니, 이제 실제로 VLA를 파인튜닝하는 방법을 다룬다. LeRobot v0.4.3 프레임워크, 플러그인 시스템, LoRA 파인튜닝 레시피, 양자화, 평가 방법론.
