# 전이학습 (Transfer Learning)

## 왜 필요한가

VLA 모델의 핵심 전략이 바로 **전이학습**이다. OpenVLA는 대규모 인터넷 데이터로 사전 학습된 Vision-Language Model(VLM)을 가져와, 상대적으로 적은 양의 로봇 조작 데이터로 **fine-tuning**하여 로봇 행동을 생성한다. 로봇 데이터만으로는 시각적 이해와 언어 이해를 처음부터 학습하기 불가능하기 때문이다. 전이학습은 VLA 파이프라인 전체를 관통하는 방법론이다.

---

## 핵심 개념

### 1. Pre-trained Models (사전 학습 모델)

대규모 데이터셋에서 미리 학습된 모델을 **사전 학습 모델**이라 한다.

- ImageNet(1400만 이미지, 1000 클래스)으로 학습된 ResNet, VGG 등이 대표적이다.
- 이 모델들은 이미지의 보편적인 특징(엣지, 텍스처, 형태, 물체 부분)을 이미 학습한 상태다.
- 보편적 특징은 특정 태스크에 국한되지 않으므로, 다른 문제에도 유용하다.
- 비유: 영어를 유창하게 구사하는 사람이 프랑스어를 배울 때, 언어의 일반적 구조에 대한 이해가 이미 있으므로 더 빨리 배운다.

### 2. Feature Extraction (특징 추출)

사전 학습 모델을 **고정된 특징 추출기**로 사용하는 방법이다.

- 사전 학습 모델의 합성곱 층(feature extractor)은 그대로 두고, **마지막 분류 층만 새로 학습**한다.
- 모든 Conv 층의 가중치가 고정(frozen)되어 업데이트되지 않는다.
- 적은 데이터로도 효과적이다. 학습할 파라미터가 매우 적기 때문이다.
- 새 태스크가 원래 태스크(ImageNet)와 유사할 때 잘 작동한다.

### 3. Fine-tuning (미세 조정)

사전 학습 모델의 일부 또는 전체를 **새 데이터에 맞게 추가 학습**하는 방법이다.

- Feature extraction보다 더 적극적인 적응 방법이다.
- 사전 학습된 가중치를 **초기값**으로 사용하고, 새 데이터로 계속 학습한다.
- 모든 가중치를 업데이트하므로 새 태스크에 더 잘 적응할 수 있다.
- 하지만 데이터가 적으면 과적합 위험이 있다.

### 4. Freezing Layers (층 동결)

Feature extraction과 full fine-tuning 사이의 **중간 전략**이다.

- 네트워크의 앞쪽(저수준 특징) 층은 **동결(freeze)** 하고, 뒤쪽(고수준 특징) 층만 학습한다.
- 직관: 엣지나 텍스처 같은 저수준 특징은 태스크에 관계없이 보편적이므로 바꿀 필요가 없다. 고수준 특징은 태스크에 따라 달라질 수 있으므로 재학습한다.
- 일반적 전략:
  - 데이터 매우 적음 → 대부분 동결, 마지막 층만 학습 (feature extraction에 가까움)
  - 데이터 보통 → 뒤쪽 절반 정도 동결 해제
  - 데이터 풍부 → 전체 fine-tuning
- **점진적 동결 해제(gradual unfreezing)**: 마지막 층부터 시작해서 점차 앞쪽 층까지 동결 해제하는 기법도 있다.

### 5. Learning Rate 차이 (Discriminative Learning Rates)

Fine-tuning 시 모든 층에 같은 학습률을 적용하는 것은 비효율적이다.

- **사전 학습 층**: 이미 좋은 가중치를 가지고 있으므로 **낮은 학습률**을 사용한다. 기존 지식을 크게 훼손하지 않기 위함이다.
- **새로 추가한 층**: 무작위 초기화 상태이므로 **높은 학습률**이 필요하다.
- 일반적으로 새 층의 학습률이 사전 학습 층의 10~100배이다.
- 예: 사전 학습 층 lr = 1e-5, 새 층 lr = 1e-3
- 이를 **discriminative learning rates** 또는 **differential learning rates**라 한다.

### 6. VLA 연결: OpenVLA의 전이학습 전략

OpenVLA는 전이학습의 현대적 적용 사례다.

- **1단계 - 사전 학습**: Prismatic VLM이 인터넷 규모의 이미지-텍스트 데이터로 시각적 이해와 언어 이해를 학습한다.
- **2단계 - Fine-tuning**: 사전 학습된 VLM을 로봇 조작 데이터(Open X-Embodiment)로 fine-tuning하여 "이미지 + 언어 명령 → 로봇 행동"을 학습한다.
- 로봇 데이터만으로는 "빨간 컵", "테이블 위"와 같은 시각-언어 개념을 학습할 수 없다. 사전 학습에서 이미 이 지식을 갖추고 있기에 소량의 로봇 데이터로도 행동을 학습할 수 있다.
- 새로운 로봇이나 환경에 적용할 때도 OpenVLA를 다시 fine-tuning한다. 이것이 전이학습의 반복적 적용이다.

---

## 연습 주제

1. ImageNet으로 학습된 ResNet-50을 의료 이미지 분류(10클래스, 데이터 500장)에 적용한다면, feature extraction과 fine-tuning 중 어떤 전략이 적합한지 논해 보라.
2. 동결할 층의 수를 결정하는 기준(데이터 양, 태스크 유사도)을 표로 정리해 보라.
3. Discriminative learning rates를 사용할 때, 층별로 학습률을 어떻게 설정할지 구체적인 예시를 설계해 보라.
4. 전이학습 없이 로봇 조작 데이터(수만 에피소드)만으로 이미지 이해를 학습하려면 어떤 문제가 발생할지 생각해 보라.
5. 사전 학습 데이터의 도메인(예: 자연 이미지)과 타겟 도메인(예: 의료 영상, 위성 사진, 로봇 카메라)이 매우 다를 때 전이학습의 효과가 어떻게 변하는지 논해 보라.

---
